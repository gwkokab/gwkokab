{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to perform analysis?\n",
    "\n",
    "This notebook contains a guide to perform analysis using GWKokab. We will recreate the analysis shared in [Eccentricity matters: Impact of eccentricity on inferred binary black hole populations](https://arxiv.org/abs/2404.08185). Data required for analysis can be generated by the [Synthetic Data Generation with GWKokab](https://github.com/gwkokab/gwkokab/blob/main/examples/synthetic_data.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"NPROC\"] = \"4\"\n",
    "os.environ[\"intra_op_parallelism_threads\"] = \"1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"cache-location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c https://raw.githubusercontent.com/gwkokab/asset-store/main/neural_vts/neural_vt_1_200_1000.eqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from jax import random as jrd, vmap\n",
    "from numpyro import distributions as dist\n",
    "from numpyro.distributions import HalfNormal\n",
    "\n",
    "from gwkokab.inference import BayesianHierarchicalModel, flowMChandler, ModelPack\n",
    "from gwkokab.models import Wysocki2019MassModel\n",
    "from gwkokab.parameters import (\n",
    "    ECCENTRICITY,\n",
    "    Parameter,\n",
    "    PRIMARY_MASS_SOURCE,\n",
    "    SECONDARY_MASS_SOURCE,\n",
    ")\n",
    "from gwkokab.vts.neuralvt import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our results reproducible, we will set the random seed to a fixed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 37\n",
    "KEY = jrd.PRNGKey(SEED)\n",
    "\n",
    "N_DIM = 5\n",
    "N_CHAINS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have five parameters to recover from the data: $\\log{(\\mathcal{R})}$, $\\alpha_m$, $m_{\\text{min}}$, $m_{\\text{max}}$, and $\\sigma$.\n",
    "\n",
    "*Note: $\\log(\\mathcal{R})$ is in common logarithms. Set your priors accordingly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_RATE = Parameter(name=\"log_rate\", prior=dist.Uniform(low=-1, high=3))\n",
    "ALPHA = Parameter(name=\"alpha_m\", prior=dist.Uniform(low=-5.0, high=5.0))\n",
    "MASS_MIN = Parameter(name=\"mmin\", prior=dist.Uniform(low=5.0, high=20.0))\n",
    "MASS_MAX = Parameter(name=\"mmax\", prior=dist.Uniform(low=30.0, high=100.0))\n",
    "SIGMA_ECC = Parameter(name=\"scale\", prior=dist.Uniform(low=0.0, high=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use `gwkokab.inference.ModelPack` to define a model.\n",
    "\n",
    "- `name`: Uninitialized `numpyro.distributions.Distribution` object.\n",
    "- `output`: Outputs of the model.\n",
    "- `parameters_to_recover`: list of `Parameter` objects to recover.\n",
    "- `arguments`: Additional arguments to the model or value of the fixed parameters.\n",
    "\n",
    "Although $\\log(\\mathcal{R})$ has no model, we define it as a model with `name=None` and `output=[]`. Using this [judaad](https://en.wikipedia.org/wiki/Jugaad) we do not have modify the `BayesianHierarchicalModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_rate_model = ModelPack(name=None, output=[], parameters_to_recover=[LOG_RATE])\n",
    "\n",
    "m1m2_model = ModelPack(\n",
    "    name=Wysocki2019MassModel,\n",
    "    output=[PRIMARY_MASS_SOURCE(), SECONDARY_MASS_SOURCE()],\n",
    "    parameters_to_recover=[ALPHA, MASS_MIN, MASS_MAX],\n",
    ")\n",
    "\n",
    "ecc_model = ModelPack(\n",
    "    name=HalfNormal,\n",
    "    output=[ECCENTRICITY()],\n",
    "    parameters_to_recover=[SIGMA_ECC],\n",
    "    arguments={\"validate_args\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to the necessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTERIOR_REGEX = os.getcwd() + r\"/data/realization_0/posteriors/event_*.dat\"\n",
    "VT_FILENAME = os.getcwd() + r\"/neural_vt_1_200_1000.eqx\"\n",
    "VT_PARAMS = [PRIMARY_MASS_SOURCE().name, SECONDARY_MASS_SOURCE().name]\n",
    "ANALYSIS_TIME = 248\n",
    "\n",
    "print(POSTERIOR_REGEX)\n",
    "print(VT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = glob(POSTERIOR_REGEX)\n",
    "data_set = {\n",
    "    \"data\": [np.loadtxt(event) for event in posteriors],\n",
    "    \"N\": len(posteriors),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logVT():\n",
    "    _, logVT = load_model(VT_FILENAME)\n",
    "    return vmap(logVT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flowMC` has variety of local samplers. To make workflow faster, flexible, and more efficient, we create a dictionary that contains a key `\"sampler\"` and a value of the sampler name, and rest of the arguments that sampler will accept, everything else will be managed by `flowMChandler`. This style of defining samplers is same for NF-model, Sampler and information required to store the meta data provided by the flowMC sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MALA_SAMPLER_KWARGS = {\n",
    "    \"sampler\": \"MALA\",\n",
    "    \"step_size\": 1e-2,\n",
    "    \"jit\": True,\n",
    "}\n",
    "\n",
    "NF_MODEL_KWARGS = {\n",
    "    \"model\": \"MaskedCouplingRQSpline\",\n",
    "    \"n_layers\": 5,\n",
    "    \"hidden_size\": [32, 32],\n",
    "    \"num_bins\": 8,\n",
    "    \"n_features\": N_DIM,\n",
    "    \"key\": KEY,\n",
    "}\n",
    "\n",
    "_, KEY = jrd.split(KEY)\n",
    "\n",
    "SAMPLER_KWARGS = {\n",
    "    \"n_dim\": N_DIM,\n",
    "    \"rng_key\": KEY,\n",
    "    \"data\": None,\n",
    "    \"n_chains\": N_CHAINS,\n",
    "    \"n_local_steps\": 100,\n",
    "    \"n_global_steps\": 65,\n",
    "    \"n_loop_training\": 20,\n",
    "    \"n_loop_production\": 20,\n",
    "    \"batch_size\": 10000,\n",
    "    \"n_epochs\": 5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "    \"precompile\": False,\n",
    "    \"verbose\": False,\n",
    "    \"use_global\": True,\n",
    "    \"logging\": True,\n",
    "    \"outdir\": \"inf-plots\",\n",
    "    # \"train_thinning\":,\n",
    "    # \"output_thinning\":,\n",
    "    # \"n_max_examples\":,\n",
    "    # \"n_flow_sample\":,\n",
    "}\n",
    "\n",
    "DATA_DUMP_KWARGS = {\n",
    "    \"out_dir\": \"sampler_data\",\n",
    "    \"labels\": [\"alpha_m\", \"mmin\", \"mmax\", \"\\sigma_ecc\", \"\\log_rate\"],\n",
    "    \"n_samples\": 10000,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `BayesianHierarchicalModel` to get the posterior function. We have to pass model in order, and model for the rate should be the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhbm = BayesianHierarchicalModel(\n",
    "    m1m2_model,\n",
    "    ecc_model,\n",
    "    log_rate_model,\n",
    "    vt_params=VT_PARAMS,\n",
    "    logVT=get_logVT(),\n",
    "    time=ANALYSIS_TIME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, KEY = jrd.split(KEY)\n",
    "\n",
    "initial_position = lhbm.population_priors.sample(KEY, (N_CHAINS,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handler for flowMC setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = flowMChandler(\n",
    "    logpdf=lhbm.log_posterior,\n",
    "    initial_position=initial_position,\n",
    "    local_sampler_kwargs=LOCAL_MALA_SAMPLER_KWARGS,\n",
    "    nf_model_kwargs=NF_MODEL_KWARGS,\n",
    "    sampler_kwargs=SAMPLER_KWARGS,\n",
    "    data_dump_kwargs=DATA_DUMP_KWARGS,\n",
    "    data=data_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
